---
title: "Sleep Disorder KNN Predictor"
author: "Daniela Frade Noguez"
date: "2025-09-25"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction
This report explores the **Sleep Health and Lifestyle Dataset** and builds a KNN model to classify sleep disorders using different lifestyle and health-related predictors. In this analysis, the target variable will be Sleep_Disorder, which classifies each individual as None, Sleep Apnea, or Insomnia.

### Predictors used:
- Age  
- Sleep Duration  
- Quality of Sleep  
- Physical Activity Level  
- Stress Level  
- Daily Steps  
- Systolic (blood pressure)  
- Diastolic (blood pressure)  
- BMI_num (numeric encoding of BMI category)  
- Gender_num (numeric encoding of gender) 


### Methods and Plan
- Clean data set  
- Visualize class distributions  
- Tune KNN model  
- Train KNN model  
- Evaluate performance with accuracy, precision, recall, and confusion matrix  
- Interpret results
- Next steps


### Load Packages and set seed for reproducibility

```{r libraries, message=FALSE, warning=FALSE}
set.seed(123)
library(tidyverse)
library(tidymodels)
library(themis)
```

### Read data set
```{r}
sleep_data <- read_csv("data/Sleep_health_and_lifestyle_dataset.csv")
head(sleep_data)
```

###  Clean data set
First we clean the data set by renaming columns, assigning numerical values to categorical variables to use them as predictors. 
```{r cleaning, message=FALSE, echo=FALSE}
sleep_data_clean <- sleep_data |>
  select(-`Person ID`, -`Heart Rate`, -`Occupation`)|>
  rename(Sleep_Disorder = `Sleep Disorder`)|>
  rename(Gender = `Gender`)|>
  rename(Age = `Age`)|>
  rename(Sleep_Duration = `Sleep Duration`)|>
  rename(Quality_of_Sleep = `Quality of Sleep`)|>
  rename(Physical_Activity_Level = `Physical Activity Level`)|>
  rename(Stress_Level = `Stress Level`)|>
  rename(BMI_Category = `BMI Category`)|>
  rename(Blood_Pressure = `Blood Pressure`)|>
  rename(Daily_Steps = `Daily Steps`)|>
  separate(Blood_Pressure, into = c("Systolic", "Diastolic"), sep = "/") |>
  mutate(Systolic = as.numeric(Systolic), Diastolic = as.numeric(Diastolic)) |>
  mutate(BMI_num = case_when(BMI_Category == "Underweight" ~ 1, 
                             BMI_Category == "Normal"~ 2,
                             BMI_Category == "Overweight"  ~ 3, 
                             BMI_Category == "Obese" ~ 4))|>
  
  mutate(Gender_num = case_when(Gender == "Male" ~ 1, 
                                Gender == "Female"~ 2))|>
  select(-BMI_Category, -Gender) |>
  
  mutate(Sleep_Disorder = as_factor(Sleep_Disorder)) |>
  drop_na()
head(sleep_data_clean)
```

###  Visualize class distributions
It is important to visualize the distribution of the target variable (Sleep_Disorder) distribution in our data set. If one category of the class has more observations than the other, the KNN model becomes biased towards that category, meaning it is more likely to predict that category. This occurs because KNN makes predictions based on the “closest” observations using euclidean distance, and the majority class will naturally have more neighbors available. From this graph we can see that there are more "none" observations in our data set, thus we will have to balance them before making any predictions to avoid bias.
```{r Visualizing class distribution, echo=FALSE}
counts_graph <- ggplot(sleep_data_clean, aes(x = Sleep_Disorder, fill = Sleep_Disorder)) + 
  geom_bar() + 
  xlab("Sleep Disorder") +
  ylab("Count") +
  ggtitle("Count of Observations per Sleep Disorder Class")+
  theme(
    axis.title = element_text(size = 20),   
    axis.text = element_text(size = 12),    
    plot.title = element_text(size = 16),  
    legend.title = element_text(size = 14),  
    legend.text = element_text(size = 12)) +
  scale_fill_manual(values = c("darkorange", "darkblue", "darkred"))
counts_graph
```

###  Tune KNN model
To make the model as accurate as possible, we need to decide how much observations (neighbors or k) it should use when classifying a new observation. We experiment with different settings of k in a range of 1 to the size of the testing set and compare how well the model performs with each. 
```{r Tuning model, echo=FALSE}
sleep_split <- initial_split(sleep_data_clean, prop = 0.75, strata = Sleep_Disorder)
sleep_training <- training(sleep_split)
sleep_testing <- testing(sleep_split)

knn_tune <- nearest_neighbor(weight_func = "rectangular", neighbors = tune()) |>
  set_engine("kknn") |>
  set_mode("classification")

k_vals <- tibble(neighbors = seq(from = 1, to = 89, by = 3))

num_vfold <- vfold_cv(sleep_training, v = 5, strata = Sleep_Disorder)

sleep_recipe <- recipe(Sleep_Disorder ~ ., data = sleep_training) |>
  step_upsample(Sleep_Disorder, over_ratio = 1, skip = TRUE) |>
  step_scale(all_predictors()) |>
  step_center(all_predictors())

knn_results <- workflow() |>
  add_recipe(sleep_recipe) |> 
  add_model(knn_tune) |>
  tune_grid(resamples = num_vfold, grid = k_vals) |>
  collect_metrics()


accuracies <- knn_results |> 
  filter(.metric == "accuracy")

k_plot <- accuracies |>
  ggplot(aes(x = neighbors, y = mean)) +
  geom_point() +
  geom_line() +
  labs(
    title = "Accuracy vs K",
    x = "Neighbors",
    y = "Accuracy Estimate"
  ) +
  scale_x_continuous(breaks = seq(0, 90, by = 5)) +
  scale_y_continuous(limits = c(0.4, 1.0)) +
  theme(
    axis.title.x = element_text(size = 18),  
    axis.title.y = element_text(size = 18),  
    axis.text = element_text(size = 12),     
    plot.title = element_text(size = 20, face = "bold") 
  )

best_k <- accuracies |>
  arrange(desc(mean)) |>
  head(1) |>
  pull(neighbors)
k_plot
best_k
```
From the plot, we can see that the number of neighbors that gives us the highest accuracy is `r best_k`.

```{r training model, echo=FALSE}
knn_model_with_best_k <- nearest_neighbor(weight_func = "rectangular", neighbors = best_k) |>
  set_engine("kknn") |>
  set_mode("classification")

knn_fit <- workflow() |>
  add_recipe(sleep_recipe) |>
  add_model(knn_model_with_best_k) |>
  fit(data = sleep_training)
```

### Evaluate performance with accuracy, precision, recall, and confusion matrix
```{r performance evaluation, echo=FALSE}
sleep_test_pred <- predict(knn_fit, sleep_testing) |>
  bind_cols(sleep_testing) 

sleep_accuracy <- sleep_test_pred |>
  metrics(truth = Sleep_Disorder, estimate = .pred_class) |>
  filter(.metric == "accuracy")

sleep_prediction <- sleep_test_pred|>
  precision(truth = Sleep_Disorder, estimate = .pred_class, event_level="first")

sleep_recall <- sleep_test_pred|>
  recall(truth = Sleep_Disorder, estimate = .pred_class, event_level="first")

confusion_matrix <- sleep_test_pred |>
  conf_mat(truth = Sleep_Disorder, estimate = .pred_class)


sleep_accuracy
sleep_prediction
sleep_recall
confusion_matrix

acc_val   <- sleep_accuracy$.estimate
prec_val  <- sleep_prediction$.estimate
recall_val <- sleep_recall$.estimate

```
### Interpretation of results

#### Results:
- Accuracy: `r acc_val`
- Precision: `r prec_val`
- Recall: `r recall_val`
- Confusion matrix: 

```{r confmat, echo=FALSE}
confusion_matrix
```

#### Interpretation:

- **Accuracy:** The model predicted the correct sleep disorder (None, Sleep Apnea, or Insomnia) `r acc_val * 100`% of the time.  
- **Precision:** On average across all classes, when the model predicted a person’s sleep disorder, it was correct `r prec_val * 100`% of the time.  
- **Recall:** On average across all classes, the model correctly identified `r recall_val * 100`% of individuals with their true sleep disorder.

##### **Confusion matrix class by class breakdown**:
###### **Class = None**
- **True Positives (TP):** 44  
- **False Positives (FP):** 7  
  - Predicted *None* when it was actually *Sleep Apnea* or *Insomnia*  
- **False Negatives (FN):** 4  
  - It was *None*, but predicted *Sleep Apnea* or *Insomnia*  


###### **Class = Sleep Apnea**
- **True Positives (TP):** 16  
- **False Positives (FP):** 3  
  - Predicted *Sleep Apnea* when it was actually *None* or *Insomnia*  
- **False Negatives (FN):** 5  
  - It was *Sleep Apnea*, but predicted *None* or *Insomnia*  

---

###### **Class = Insomnia**
- **True Positives (TP):** 15  
- **False Positives (FP):** 4  
  - Predicted *Insomnia* when it was actually *None* or *Sleep Apnea*  
- **False Negatives (FN):** 3  
  - It was *Insomnia*, but predicted *None* or *Sleep Apnea* 

### Next Steps
Overall, the model is effective however it may benefit by tuning it to optimize recall. This way, we minimize the amounts of false negatives and we avoid diagnosing someone with no sleep disorder when they may be at risk of one. 


### References

Kaggle. (2025). Lifestyle and Sleep Patterns [Data set]. Kaggle. 
https://www.kaggle.com/datasets/minahilfatima12328/lifestyle-and-sleep-patterns

Timbers, T., Campbell, T., & Lee, M. (2024). Data science: A first introduction.
